syntax = "proto3";

import "google/protobuf/empty.proto";

package nos.inference;


message ModelListResponse {
  repeated string models = 1;
}


message ModelInfoRequest {
  string model_name = 1;
}

message ModelInfoResponse {
}


message TextRequest {
  string text = 1;
}


message ImageRequest {
  bytes image_bytes = 1;
}


message InitModelRequest {
  string model_name = 1;
  optional int32 num_replicas = 2;
}


message InitModelResponse {
  string result = 1;
}


message DeleteModelRequest {
  string model_name = 1;
}


message DeleteModelResponse {
  string result = 1;
}


message InferenceRequest {
  string method = 1;
  string model_name = 2;
  oneof request {
    TextRequest text_request = 3;
    ImageRequest image_request = 4;
  }
}


message InferenceResponse {
  bytes result = 1;
}

// Service definition
service InferenceService {
  // List available models from Hugging Face Hub
  rpc ListModels(google.protobuf.Empty) returns (ModelListResponse) {};

  // Load model from Hugging Face Hub
  rpc InitModel(InitModelRequest) returns (InitModelResponse) {}

  // Delete model from deployment
  rpc DeleteModel(DeleteModelRequest) returns (DeleteModelResponse) {}

  // Get model information from the deployment
  rpc GetModelInfo(ModelInfoRequest) returns (ModelInfoResponse) {};

  // Perform text-to-vector prediction
  rpc Predict(InferenceRequest) returns (InferenceResponse) {}
}
