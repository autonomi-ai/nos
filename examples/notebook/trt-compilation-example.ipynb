{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4ee344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /root/.pyenv/versions/3.10.12/lib/python3.10/site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.0.1\n",
      "    Uninstalling pip-23.0.1:\n",
      "      Successfully uninstalled pip-23.0.1\n",
      "Successfully installed pip-23.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting loguru\n",
      "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /root/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from opencv-python-headless) (1.24.3)\n",
      "Installing collected packages: tabulate, opencv-python-headless, loguru\n",
      "Successfully installed loguru-0.7.0 opencv-python-headless-4.7.0.72 tabulate-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install loguru opencv-python-headless tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4efb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.fx\n",
    "import torch.nn as nn\n",
    "from torch_tensorrt.fx.utils import LowerPrecision\n",
    "import torch_tensorrt.fx.tracer.acc_tracer.acc_tracer as acc_tracer\n",
    "from torch_tensorrt.fx import InputTensorSpec, TRTInterpreter, TRTModule\n",
    "from torch_tensorrt.fx.tools.trt_splitter import TRTSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d91707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/Megvii-BaseDetection_YOLOX_main\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"Megvii-BaseDetection/YOLOX\", \"yolox_nano\").cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e84d74a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOPAFPN(\n",
       "  (backbone): CSPDarknet(\n",
       "    (stem): Focus(\n",
       "      (conv): BaseConv(\n",
       "        (conv): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dark2): Sequential(\n",
       "      (0): DWConv(\n",
       "        (dconv): BaseConv(\n",
       "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (pconv): BaseConv(\n",
       "          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): CSPLayer(\n",
       "        (conv1): BaseConv(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): BaseConv(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): BaseConv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): BaseConv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2): DWConv(\n",
       "              (dconv): BaseConv(\n",
       "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "                (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (pconv): BaseConv(\n",
       "                (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dark3): Sequential(\n",
       "      (0): DWConv(\n",
       "        (dconv): BaseConv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (pconv): BaseConv(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): CSPLayer(\n",
       "        (conv1): BaseConv(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): BaseConv(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): BaseConv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): BaseConv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2): DWConv(\n",
       "              (dconv): BaseConv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (pconv): BaseConv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): BaseConv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2): DWConv(\n",
       "              (dconv): BaseConv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (pconv): BaseConv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): BaseConv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2): DWConv(\n",
       "              (dconv): BaseConv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (pconv): BaseConv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dark4): Sequential(\n",
       "      (0): DWConv(\n",
       "        (dconv): BaseConv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (pconv): BaseConv(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): CSPLayer(\n",
       "        (conv1): BaseConv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): BaseConv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): BaseConv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): BaseConv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2): DWConv(\n",
       "              (dconv): BaseConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (pconv): BaseConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): BaseConv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2): DWConv(\n",
       "              (dconv): BaseConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (pconv): BaseConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): BaseConv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2): DWConv(\n",
       "              (dconv): BaseConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (pconv): BaseConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dark5): Sequential(\n",
       "      (0): DWConv(\n",
       "        (dconv): BaseConv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (pconv): BaseConv(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SPPBottleneck(\n",
       "        (conv1): BaseConv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "          (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "          (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (conv2): BaseConv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): CSPLayer(\n",
       "        (conv1): BaseConv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): BaseConv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): BaseConv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): BaseConv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv2): DWConv(\n",
       "              (dconv): BaseConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (pconv): BaseConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "  (lateral_conv0): BaseConv(\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (C3_p4): CSPLayer(\n",
       "    (conv1): BaseConv(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (conv2): BaseConv(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (conv3): BaseConv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): BaseConv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): DWConv(\n",
       "          (dconv): BaseConv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (pconv): BaseConv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (reduce_conv1): BaseConv(\n",
       "    (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (C3_p3): CSPLayer(\n",
       "    (conv1): BaseConv(\n",
       "      (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (conv2): BaseConv(\n",
       "      (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (conv3): BaseConv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): BaseConv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): DWConv(\n",
       "          (dconv): BaseConv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (pconv): BaseConv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bu_conv2): DWConv(\n",
       "    (dconv): BaseConv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (pconv): BaseConv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (C3_n3): CSPLayer(\n",
       "    (conv1): BaseConv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (conv2): BaseConv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (conv3): BaseConv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): BaseConv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): DWConv(\n",
       "          (dconv): BaseConv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (pconv): BaseConv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bu_conv1): DWConv(\n",
       "    (dconv): BaseConv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (pconv): BaseConv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (C3_n4): CSPLayer(\n",
       "    (conv1): BaseConv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (conv2): BaseConv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (conv3): BaseConv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): BaseConv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): DWConv(\n",
       "          (dconv): BaseConv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (pconv): BaseConv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a44cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [torch.randn((1, 3, 480, 640), device=torch.device(\"cuda\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a2c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/fx/operator_schemas.py:194: UserWarning: We were not able to successfully create type hint from the type (<class 'ellipsis'>, slice(<class 'NoneType'>, <class 'NoneType'>, <class 'int'>), slice(<class 'NoneType'>, <class 'NoneType'>, <class 'int'>))\n",
      "  warnings.warn(f\"We were not able to successfully create type hint from the type {x}\")\n",
      "/root/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/fx/operator_schemas.py:194: UserWarning: We were not able to successfully create type hint from the type (<class 'ellipsis'>, slice(<class 'NoneType'>, <class 'NoneType'>, <class 'int'>), slice(<class 'int'>, <class 'NoneType'>, <class 'int'>))\n",
      "  warnings.warn(f\"We were not able to successfully create type hint from the type {x}\")\n",
      "/root/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/fx/operator_schemas.py:194: UserWarning: We were not able to successfully create type hint from the type (<class 'ellipsis'>, slice(<class 'int'>, <class 'NoneType'>, <class 'int'>), slice(<class 'NoneType'>, <class 'NoneType'>, <class 'int'>))\n",
      "  warnings.warn(f\"We were not able to successfully create type hint from the type {x}\")\n",
      "/root/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/fx/operator_schemas.py:194: UserWarning: We were not able to successfully create type hint from the type (<class 'ellipsis'>, slice(<class 'int'>, <class 'NoneType'>, <class 'int'>), slice(<class 'int'>, <class 'NoneType'>, <class 'int'>))\n",
      "  warnings.warn(f\"We were not able to successfully create type hint from the type {x}\")\n"
     ]
    }
   ],
   "source": [
    "# acc_tracer is a custom fx tracer that maps nodes whose targets are PyTorch operators\n",
    "# to acc ops.\n",
    "traced = acc_tracer.trace(model.backbone, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4910fa54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (backbone): Module(\n",
       "    (stem): Module(\n",
       "      (conv): Module(\n",
       "        (conv): Module()\n",
       "        (bn): Module()\n",
       "      )\n",
       "    )\n",
       "    (dark2): Module(\n",
       "      (0): Module(\n",
       "        (dconv): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (pconv): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (m): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Module()\n",
       "              (bn): Module()\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (dconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "              (pconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (conv3): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dark3): Module(\n",
       "      (0): Module(\n",
       "        (dconv): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (pconv): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (m): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Module()\n",
       "              (bn): Module()\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (dconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "              (pconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Module()\n",
       "              (bn): Module()\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (dconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "              (pconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Module()\n",
       "              (bn): Module()\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (dconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "              (pconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (conv3): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dark4): Module(\n",
       "      (0): Module(\n",
       "        (dconv): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (pconv): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (m): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Module()\n",
       "              (bn): Module()\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (dconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "              (pconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Module()\n",
       "              (bn): Module()\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (dconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "              (pconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Module()\n",
       "              (bn): Module()\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (dconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "              (pconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (conv3): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dark5): Module(\n",
       "      (0): Module(\n",
       "        (dconv): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (pconv): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (m): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Module()\n",
       "              (bn): Module()\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (dconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "              (pconv): Module(\n",
       "                (conv): Module()\n",
       "                (bn): Module()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (conv3): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lateral_conv0): Module(\n",
       "    (conv): Module()\n",
       "    (bn): Module()\n",
       "  )\n",
       "  (C3_p4): Module(\n",
       "    (conv1): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (conv2): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (m): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (dconv): Module(\n",
       "            (conv): Module()\n",
       "            (bn): Module()\n",
       "          )\n",
       "          (pconv): Module(\n",
       "            (conv): Module()\n",
       "            (bn): Module()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv3): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "  )\n",
       "  (reduce_conv1): Module(\n",
       "    (conv): Module()\n",
       "    (bn): Module()\n",
       "  )\n",
       "  (C3_p3): Module(\n",
       "    (conv1): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (conv2): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (m): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (dconv): Module(\n",
       "            (conv): Module()\n",
       "            (bn): Module()\n",
       "          )\n",
       "          (pconv): Module(\n",
       "            (conv): Module()\n",
       "            (bn): Module()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv3): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "  )\n",
       "  (bu_conv2): Module(\n",
       "    (dconv): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (pconv): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "  )\n",
       "  (C3_n3): Module(\n",
       "    (conv1): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (conv2): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (m): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (dconv): Module(\n",
       "            (conv): Module()\n",
       "            (bn): Module()\n",
       "          )\n",
       "          (pconv): Module(\n",
       "            (conv): Module()\n",
       "            (bn): Module()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv3): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "  )\n",
       "  (bu_conv1): Module(\n",
       "    (dconv): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (pconv): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "  )\n",
       "  (C3_n4): Module(\n",
       "    (conv1): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (conv2): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "    (m): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Module()\n",
       "          (bn): Module()\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (dconv): Module(\n",
       "            (conv): Module()\n",
       "            (bn): Module()\n",
       "          )\n",
       "          (pconv): Module(\n",
       "            (conv): Module()\n",
       "            (bn): Module()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv3): Module(\n",
       "      (conv): Module()\n",
       "      (bn): Module()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1803e325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_tensorrt.fx.tools.trt_splitter.TRTSplitter at 0x7f3f7c3b3a00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitter will split the model into several submodules. The name of submodules will\n",
    "# be either `run_on_acc_{}` or `run_on_gpu_{}`. Submodules named `run_on_acc_{}` can\n",
    "# be fully lowered to TensorRT via fx2trt while submodules named `run_on_gpu_{}` has\n",
    "# unsupported ops and can't be lowered by fx2trt. We can still run `run_on_gpu_{}`\n",
    "# submodules on Gpu if ops there have cuda implementation, the naming is a bit\n",
    "# confusing and we'll improve it.\n",
    "splitter = TRTSplitter(traced, inputs)\n",
    "splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc4eed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PCIe_BW',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_draw_graph_based_on_node_support',\n",
       " '_find_culprit',\n",
       " '_lower_model_to_backend',\n",
       " '_node_submodule_map',\n",
       " 'acc_nodes',\n",
       " 'deps',\n",
       " 'extend_acc_subgraph',\n",
       " 'find_deps',\n",
       " 'find_parent_nodes_of_subgraph',\n",
       " 'find_reverse_deps',\n",
       " 'fusions',\n",
       " 'generate_split_results',\n",
       " 'get_node_submodule_map',\n",
       " 'module',\n",
       " 'node_support_preview',\n",
       " 'non_acc_submodule_name',\n",
       " 'operator_support',\n",
       " 'put_nodes_into_subgraphs',\n",
       " 'remove_small_acc_subgraphs',\n",
       " 'sample_input',\n",
       " 'settings',\n",
       " 'split',\n",
       " 'split_preview',\n",
       " 'starter_nodes',\n",
       " 'tag',\n",
       " 'update_deps_for_fusions',\n",
       " 'update_reverse_deps_for_fusions']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23b12b19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_run_on_gpu_'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.non_acc_submodule_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94f5d6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Supported node types in the model:\n",
      "acc_ops.getitem: ((), {'input': torch.float32})\n",
      "acc_ops.cat: ((), {})\n",
      "acc_ops.conv2d: ((), {'input': torch.float32, 'weight': torch.float32})\n",
      "acc_ops.batch_norm: ((), {'input': torch.float32, 'running_mean': torch.float32, 'running_var': torch.float32, 'weight': torch.float32, 'bias': torch.float32})\n",
      "acc_ops.sigmoid: ((), {'input': torch.float32})\n",
      "acc_ops.mul: ((), {'input': torch.float32, 'other': torch.float32})\n",
      "acc_ops.add: ((), {'input': torch.float32, 'other': torch.float32})\n",
      "acc_ops.max_pool2d: ((), {'input': torch.float32})\n",
      "acc_ops.interpolate: ((), {'input': torch.float32})\n",
      "\n",
      "Unsupported node types in the model:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nSupported node types in the model:\\nacc_ops.getitem: ((), {'input': torch.float32})\\nacc_ops.cat: ((), {})\\nacc_ops.conv2d: ((), {'input': torch.float32, 'weight': torch.float32})\\nacc_ops.batch_norm: ((), {'input': torch.float32, 'running_mean': torch.float32, 'running_var': torch.float32, 'weight': torch.float32, 'bias': torch.float32})\\nacc_ops.sigmoid: ((), {'input': torch.float32})\\nacc_ops.mul: ((), {'input': torch.float32, 'other': torch.float32})\\nacc_ops.add: ((), {'input': torch.float32, 'other': torch.float32})\\nacc_ops.max_pool2d: ((), {'input': torch.float32})\\nacc_ops.interpolate: ((), {'input': torch.float32})\\n\\nUnsupported node types in the model:\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview functionality allows us to see what are the supported ops and unsupported\n",
    "# ops. We can optionally the dot graph which will color supported ops and unsupported\n",
    "# ops differently.\n",
    "splitter.node_support_preview(dump_graph=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d0c5007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1 acc subgraphs and 0 non-acc subgraphs\n"
     ]
    }
   ],
   "source": [
    "# Split.\n",
    "split_mod = splitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab95a1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %input_1 : [#users=1] = placeholder[target=input_1]\n",
      "    %_run_on_acc_0 : [#users=3] = call_module[target=_run_on_acc_0](args = (%input_1,), kwargs = {})\n",
      "    %getitem : [#users=1] = call_function[target=operator.getitem](args = (%_run_on_acc_0, 0), kwargs = {})\n",
      "    %getitem_1 : [#users=1] = call_function[target=operator.getitem](args = (%_run_on_acc_0, 1), kwargs = {})\n",
      "    %getitem_2 : [#users=1] = call_function[target=operator.getitem](args = (%_run_on_acc_0, 2), kwargs = {})\n",
      "    return (getitem, getitem_1, getitem_2)\n"
     ]
    }
   ],
   "source": [
    "# After split we have three submodules, _run_on_acc_0 and _run_on_gpu_1.\n",
    "print(split_mod.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad38c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/09/2023-23:48:01] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch_tensorrt.fx.fx2trt:TRT INetwork construction elapsed time: 0:00:05.171293\n",
      "INFO:torch_tensorrt.fx.fx2trt:Build TRT engine elapsed time: 0:01:12.171480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/09/2023-23:49:18] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_submod_inputs(mod, submod, inputs):\n",
    "    acc_inputs = None\n",
    "\n",
    "    def get_input(self, inputs):\n",
    "        nonlocal acc_inputs\n",
    "        acc_inputs = inputs\n",
    "\n",
    "    handle = submod.register_forward_pre_hook(get_input)\n",
    "    mod(*inputs)\n",
    "    handle.remove()\n",
    "    return acc_inputs\n",
    "\n",
    "\n",
    "# Since the model is splitted into three segments. We need to lower each TRT eligible segment.\n",
    "# If we know the model can be fully lowered, we can skip the splitter part.\n",
    "for name, _ in split_mod.named_children():\n",
    "    if \"_run_on_acc\" in name:\n",
    "        submod = getattr(split_mod, name)\n",
    "        # Get submodule inputs for fx2trt\n",
    "        acc_inputs = get_submod_inputs(split_mod, submod, inputs)\n",
    "\n",
    "        # fx2trt replacement\n",
    "        interp = TRTInterpreter(\n",
    "            submod,\n",
    "            InputTensorSpec.from_tensors(acc_inputs),\n",
    "            explicit_batch_dimension=True,\n",
    "        )\n",
    "        r = interp.run(lower_precision=LowerPrecision.FP32)\n",
    "        trt_mod = TRTModule(*r)\n",
    "        setattr(split_mod, name, trt_mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d42bd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/09/2023-23:49:47] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lowered_model_output = split_mod(*inputs)\n",
    "\n",
    "# Save and load model\n",
    "torch.save(split_mod, \"trt.pt\")\n",
    "reload_trt_mod = torch.load(\"trt.pt\")\n",
    "reload_model_output = reload_trt_mod(*inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e028343b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-8.9316e-02, -2.2630e-01,  1.5959e-01,  ...,  6.4901e-01,\n",
       "             4.1133e-01,  2.4447e-01],\n",
       "           [-9.0794e-02, -2.5189e-01,  2.3452e-02,  ...,  2.8365e-01,\n",
       "            -7.1280e-02,  3.4402e-02],\n",
       "           [-1.4922e-01, -1.5998e-01,  2.4949e-01,  ...,  1.0765e-01,\n",
       "            -5.0098e-02,  3.9327e-01],\n",
       "           ...,\n",
       "           [ 6.6856e-02, -1.3786e-01,  3.6274e-01,  ..., -8.5888e-02,\n",
       "            -2.2017e-01, -2.4735e-01],\n",
       "           [-8.3339e-02, -1.9668e-01,  4.3444e-02,  ..., -1.5990e-01,\n",
       "            -1.9910e-01, -2.7598e-01],\n",
       "           [ 3.8716e-02, -1.9877e-01,  1.0792e-02,  ..., -2.2676e-02,\n",
       "            -1.3005e-01, -2.6546e-01]],\n",
       " \n",
       "          [[-8.5041e-02,  4.3165e-01,  6.0169e-01,  ...,  4.6086e-01,\n",
       "             3.0016e-01, -9.7433e-02],\n",
       "           [ 3.4876e-01,  1.3553e+00,  1.0851e+00,  ...,  7.7728e-01,\n",
       "             4.9340e-01, -1.8551e-01],\n",
       "           [ 1.0991e-01,  3.2507e-01,  8.4735e-02,  ...,  4.2321e-01,\n",
       "            -7.3836e-02, -2.7390e-01],\n",
       "           ...,\n",
       "           [-2.7594e-01, -2.2001e-01, -3.9917e-02,  ...,  1.6739e+00,\n",
       "             8.2698e-01, -1.5748e-01],\n",
       "           [-2.4184e-01, -2.7558e-01, -2.6640e-01,  ...,  2.0028e+00,\n",
       "             7.6657e-01, -2.7632e-01],\n",
       "           [-2.6908e-01, -2.6385e-01, -2.7443e-01,  ...,  3.6610e-02,\n",
       "            -2.5234e-01, -2.7128e-01]],\n",
       " \n",
       "          [[-2.4019e-01,  5.7444e-02,  2.3286e-01,  ...,  5.7336e-01,\n",
       "             4.1394e-01, -5.7246e-02],\n",
       "           [-2.7599e-01,  4.0110e-01,  3.3475e-01,  ...,  5.7596e-01,\n",
       "             2.2956e-01, -2.2369e-01],\n",
       "           [-2.4768e-01,  3.2804e-01,  3.1749e-01,  ...,  2.8845e-01,\n",
       "             4.1755e-01, -1.4301e-01],\n",
       "           ...,\n",
       "           [-2.6747e-01,  1.1302e-01,  5.3830e-02,  ...,  1.8905e+00,\n",
       "             1.3644e+00,  1.5013e-01],\n",
       "           [-2.7829e-01,  7.4205e-02,  1.6943e-02,  ...,  1.5387e+00,\n",
       "             5.5508e-01, -2.5568e-01],\n",
       "           [-1.7822e-01,  9.1199e-02, -5.0553e-02,  ...,  3.1222e-01,\n",
       "            -1.7486e-01, -2.5195e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.8976e-02,  4.5645e-02,  5.2280e-01,  ...,  5.3178e-01,\n",
       "             5.3640e-01,  2.0162e-01],\n",
       "           [ 6.6342e-01, -4.9396e-02,  1.5728e-01,  ...,  2.5188e-01,\n",
       "             2.5138e-01, -1.4642e-01],\n",
       "           [ 3.4097e-01, -1.1621e-01, -2.7682e-02,  ..., -2.7186e-03,\n",
       "            -5.9839e-04, -1.9886e-01],\n",
       "           ...,\n",
       "           [ 5.7555e-01,  2.0183e-01,  7.2528e-01,  ..., -2.7265e-01,\n",
       "            -2.5705e-01, -2.7646e-01],\n",
       "           [ 4.5480e-01,  9.8698e-02,  3.5866e-01,  ..., -2.3757e-01,\n",
       "            -2.5344e-01, -1.8903e-01],\n",
       "           [ 8.0992e-01,  3.5026e-01,  5.2273e-01,  ...,  3.8950e-01,\n",
       "             2.4173e-01,  3.4921e-01]],\n",
       " \n",
       "          [[-2.4407e-01, -2.7026e-01, -2.5863e-01,  ..., -8.4221e-02,\n",
       "            -3.3108e-02, -2.3104e-01],\n",
       "           [-2.7508e-01, -2.5878e-01, -2.6326e-01,  ..., -1.4291e-01,\n",
       "            -2.0777e-01, -2.7306e-01],\n",
       "           [-2.5984e-01, -2.7686e-01, -1.9319e-01,  ..., -3.7904e-02,\n",
       "            -1.9688e-01, -2.7842e-01],\n",
       "           ...,\n",
       "           [-2.6349e-01, -2.0524e-01, -1.1148e-01,  ...,  8.3410e-01,\n",
       "             9.4288e-01,  4.8943e-01],\n",
       "           [-2.5236e-01, -2.1641e-01, -6.0747e-02,  ...,  2.0254e+00,\n",
       "             1.3306e+00,  1.1218e+00],\n",
       "           [-1.1936e-01, -9.8470e-02, -7.3961e-02,  ...,  1.8259e+00,\n",
       "             1.2010e+00,  9.9898e-01]],\n",
       " \n",
       "          [[-2.5386e-02,  1.6975e-01,  5.4091e-01,  ...,  7.3128e-01,\n",
       "             6.5081e-01,  3.8358e-01],\n",
       "           [-1.8002e-01, -7.5083e-02,  3.0586e-01,  ...,  5.3904e-01,\n",
       "             2.9483e-01,  8.8993e-02],\n",
       "           [-2.2279e-02,  1.2719e-01,  6.0846e-01,  ...,  7.2127e-01,\n",
       "             3.8330e-01,  1.3976e-01],\n",
       "           ...,\n",
       "           [ 2.6674e-01,  3.4066e-01,  4.6930e-01,  ...,  1.7040e+00,\n",
       "             1.3468e+00,  1.4043e+00],\n",
       "           [ 4.3844e-01,  5.0483e-01,  7.0481e-01,  ...,  1.3046e+00,\n",
       "             9.3607e-01,  1.0536e+00],\n",
       "           [ 7.3947e-01,  8.4043e-01,  9.6742e-01,  ...,  1.6565e+00,\n",
       "             1.2917e+00,  1.4008e+00]]]], device='cuda:0'),\n",
       " tensor([[[[ 1.4196e+00,  1.2411e+00,  7.4888e-01,  ...,  9.5973e-01,\n",
       "             5.2745e-01,  5.2202e-01],\n",
       "           [ 1.0296e+00,  2.9992e-01, -4.8819e-02,  ...,  1.4119e-02,\n",
       "             2.4739e-04,  7.9113e-01],\n",
       "           [ 6.4218e-01,  2.2294e-02,  2.4393e-01,  ...,  1.8188e-01,\n",
       "             2.0495e-01,  6.6768e-01],\n",
       "           ...,\n",
       "           [ 1.5692e+00,  9.7439e-01,  5.5609e-01,  ...,  3.5082e-01,\n",
       "            -5.1520e-03, -1.5782e-02],\n",
       "           [ 2.2415e+00,  2.0382e+00,  1.6599e+00,  ...,  4.3746e-01,\n",
       "             1.5532e-01, -1.1903e-01],\n",
       "           [ 2.0913e+00,  1.6907e+00,  1.0553e+00,  ...,  1.0702e+00,\n",
       "             1.7876e+00,  7.5837e-01]],\n",
       " \n",
       "          [[-1.0950e-01,  8.7775e-02,  1.0944e+00,  ...,  2.6160e-01,\n",
       "            -2.6450e-01, -1.6246e-01],\n",
       "           [-2.3514e-01, -2.0498e-01,  5.8865e-02,  ..., -7.2931e-02,\n",
       "            -2.0884e-01, -1.6343e-01],\n",
       "           [-1.0497e-01, -2.6921e-01, -2.7833e-01,  ..., -2.3669e-01,\n",
       "            -1.6035e-01,  5.5739e-03],\n",
       "           ...,\n",
       "           [ 4.4239e-01, -7.4397e-02, -2.7812e-01,  ..., -1.2419e-01,\n",
       "             3.7532e-02, -1.5701e-01],\n",
       "           [-1.9686e-01, -1.3224e-01, -5.1788e-02,  ...,  9.5608e-01,\n",
       "             5.5356e+00,  5.2914e+00],\n",
       "           [ 3.4964e-01,  1.1950e-01,  2.2043e-01,  ...,  7.6810e-01,\n",
       "             6.2014e+00,  5.9900e+00]],\n",
       " \n",
       "          [[-2.7821e-01, -2.5020e-01,  6.9236e-01,  ...,  1.1242e+00,\n",
       "             6.3314e-01,  5.1262e-01],\n",
       "           [-5.3243e-02, -1.8928e-01, -1.3830e-01,  ...,  1.1900e+00,\n",
       "             4.5237e-01,  4.5217e-01],\n",
       "           [ 3.1041e-01, -2.3457e-01, -1.9441e-01,  ...,  1.9905e-01,\n",
       "             8.7120e-01,  1.5975e+00],\n",
       "           ...,\n",
       "           [ 1.1306e+00, -4.9287e-02,  3.5866e-01,  ...,  2.4953e-01,\n",
       "            -1.1235e-01,  3.2275e-01],\n",
       "           [-5.8634e-02, -6.4817e-02, -2.6538e-01,  ..., -2.5160e-01,\n",
       "            -1.5461e-01, -1.0191e-01],\n",
       "           [ 3.2479e+00,  1.6506e+00,  4.1640e-01,  ...,  1.5033e-01,\n",
       "             3.6854e+00,  3.3754e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 8.9644e-01, -1.2084e-01,  1.6629e-01,  ...,  4.4217e-01,\n",
       "            -5.6225e-02,  3.5207e-01],\n",
       "           [-2.2012e-01,  1.1093e-01, -2.1838e-01,  ..., -7.4952e-02,\n",
       "            -6.1913e-02,  1.2639e-03],\n",
       "           [-1.4931e-01,  1.3140e-02,  1.9761e-01,  ..., -1.7807e-01,\n",
       "            -1.3799e-01,  8.3541e-02],\n",
       "           ...,\n",
       "           [ 1.3665e+00,  7.6478e-01,  7.9204e-02,  ..., -2.3664e-01,\n",
       "            -2.0284e-01, -2.5536e-01],\n",
       "           [ 2.2915e+00,  1.5977e+00,  1.1242e+00,  ..., -2.7087e-01,\n",
       "            -2.6864e-01, -2.6899e-01],\n",
       "           [ 1.4394e+00,  1.4544e+00,  9.1037e-01,  ...,  5.0467e-01,\n",
       "             1.0951e-01,  1.1628e-01]],\n",
       " \n",
       "          [[ 1.0276e+00,  1.4584e-01, -7.6975e-02,  ..., -9.5840e-02,\n",
       "             1.6796e-01,  4.9617e-01],\n",
       "           [ 1.6853e+00,  2.9446e-01,  2.4844e-02,  ...,  3.2374e-01,\n",
       "             2.2056e-02,  8.4235e-01],\n",
       "           [ 1.1248e+00, -8.3048e-03, -2.3045e-01,  ..., -2.3855e-01,\n",
       "             7.0299e-02, -7.7251e-02],\n",
       "           ...,\n",
       "           [ 1.4720e+00,  3.0334e-01,  1.2859e-01,  ..., -2.2120e-01,\n",
       "            -2.3514e-01, -2.7405e-01],\n",
       "           [ 2.5349e-01,  9.7927e-01,  2.4441e-01,  ...,  2.8223e-01,\n",
       "            -2.5541e-01,  3.9324e-01],\n",
       "           [ 7.6068e-02,  2.1151e-01,  6.3329e-01,  ...,  7.0690e-01,\n",
       "            -2.0614e-01, -2.2278e-01]],\n",
       " \n",
       "          [[ 4.3720e-01, -1.5305e-01,  3.4965e-01,  ...,  5.2667e-01,\n",
       "            -1.7446e-01, -2.5282e-01],\n",
       "           [-2.7008e-01, -2.7139e-01, -2.0164e-01,  ..., -2.6421e-01,\n",
       "            -2.4462e-01, -2.6081e-01],\n",
       "           [ 7.1716e-02, -2.7226e-01, -1.5072e-01,  ...,  2.2025e-02,\n",
       "            -2.0260e-01, -2.5538e-01],\n",
       "           ...,\n",
       "           [-2.7287e-01, -2.5085e-01,  6.7673e-01,  ..., -2.6575e-01,\n",
       "            -2.5875e-01, -2.7035e-01],\n",
       "           [-2.0065e-01, -2.7624e-01, -2.7758e-01,  ..., -2.7570e-01,\n",
       "             3.0530e-01,  3.9951e-01],\n",
       "           [-2.1793e-01, -2.7830e-01, -2.7694e-01,  ..., -5.0043e-02,\n",
       "            -2.6549e-01, -2.4621e-01]]]], device='cuda:0'),\n",
       " tensor([[[[ 0.9365,  1.7861,  1.3333,  ...,  0.5927,  1.8696,  1.8671],\n",
       "           [-0.1673,  0.6002,  0.5831,  ...,  0.5089,  2.6200,  0.3252],\n",
       "           [ 0.4387,  0.3904,  0.1248,  ...,  0.7389,  1.3303,  0.1603],\n",
       "           ...,\n",
       "           [ 0.2500,  0.7189,  0.4027,  ..., -0.1056,  0.9642,  1.8497],\n",
       "           [ 0.6153,  0.9169,  0.2279,  ...,  0.4258,  1.0291,  0.4157],\n",
       "           [ 0.5650,  0.1716,  0.5172,  ...,  0.6065,  1.0137,  1.4260]],\n",
       " \n",
       "          [[ 1.2178,  0.1661,  0.3809,  ...,  0.3762, -0.1585,  0.9139],\n",
       "           [-0.1801, -0.2626, -0.2129,  ..., -0.2105, -0.2060, -0.2408],\n",
       "           [ 0.1954, -0.0885, -0.2678,  ..., -0.1644, -0.2670, -0.2762],\n",
       "           ...,\n",
       "           [ 2.2625, -0.2773,  0.8172,  ...,  0.9387, -0.2723,  2.4295],\n",
       "           [ 1.0056,  0.0093, -0.0743,  ...,  1.5781, -0.0080,  0.5123],\n",
       "           [ 2.8558, -0.1721, -0.0130,  ...,  1.1694,  1.0395,  2.7910]],\n",
       " \n",
       "          [[ 2.4605,  2.3048,  2.3619,  ...,  0.6990,  3.4312,  3.3843],\n",
       "           [ 2.0045,  1.6280, -0.1945,  ..., -0.2773,  3.0664,  4.5833],\n",
       "           [-0.0269,  2.6203,  0.8607,  ...,  0.0217,  1.4927,  1.5672],\n",
       "           ...,\n",
       "           [ 0.1082, -0.2448, -0.2727,  ..., -0.1483, -0.2777, -0.2075],\n",
       "           [ 0.9261,  0.0213, -0.2562,  ..., -0.2533, -0.1365, -0.0966],\n",
       "           [ 0.6927,  3.2408,  0.7056,  ..., -0.1741,  0.1407, -0.1126]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1801,  1.2029,  0.3062,  ...,  0.6290, -0.2778,  1.8525],\n",
       "           [ 1.2890, -0.1003, -0.2717,  ...,  0.2068,  0.5444,  2.5355],\n",
       "           [ 0.1836,  1.5987, -0.2563,  ..., -0.1052,  0.1668,  2.0619],\n",
       "           ...,\n",
       "           [-0.0661,  0.9654, -0.1928,  ...,  0.2389,  0.1371, -0.2333],\n",
       "           [ 0.1031,  0.0278,  0.9255,  ...,  0.3021, -0.1792, -0.2083],\n",
       "           [ 0.6043,  0.9157,  0.3474,  ..., -0.2750, -0.0758, -0.1914]],\n",
       " \n",
       "          [[-0.2337, -0.2250, -0.2406,  ..., -0.2784, -0.1381, -0.1911],\n",
       "           [-0.2766, -0.0745,  0.0138,  ..., -0.2439,  0.1886, -0.2591],\n",
       "           [-0.1796,  0.0266,  0.3345,  ..., -0.0807, -0.0679, -0.0501],\n",
       "           ...,\n",
       "           [ 2.9486,  1.5905,  0.6279,  ...,  0.5942,  0.0714,  4.1355],\n",
       "           [ 1.9498,  1.9244,  1.5525,  ...,  1.3604,  0.8404,  1.8832],\n",
       "           [ 1.3873,  1.2144,  0.1948,  ...,  0.9053,  0.3683, -0.0913]],\n",
       " \n",
       "          [[ 0.3782,  1.2957,  0.9833,  ..., -0.2465,  3.9561,  0.0779],\n",
       "           [ 0.5077,  0.5353,  0.5791,  ..., -0.1999, -0.2780, -0.0666],\n",
       "           [-0.2393, -0.0569, -0.0244,  ..., -0.2754,  0.5080, -0.2600],\n",
       "           ...,\n",
       "           [-0.2770, -0.2710, -0.2383,  ..., -0.2332, -0.1153, -0.0757],\n",
       "           [-0.2739, -0.2579,  0.0789,  ..., -0.2772, -0.2754, -0.2489],\n",
       "           [-0.2581, -0.1301,  0.6984,  ...,  2.3137,  0.5511,  0.1935]]]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7606dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the results match\n",
    "regular_model_output = model.backbone(*inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a94394b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-7.5837e-02, -2.3319e-01,  1.5376e-01,  ...,  6.4456e-01,\n",
       "             4.0561e-01,  2.5368e-01],\n",
       "           [-9.1250e-02, -2.5452e-01,  2.2328e-02,  ...,  2.6407e-01,\n",
       "            -8.5649e-02,  3.2721e-02],\n",
       "           [-1.5058e-01, -1.6837e-01,  2.4238e-01,  ...,  9.2854e-02,\n",
       "            -6.9895e-02,  4.0667e-01],\n",
       "           ...,\n",
       "           [ 5.4107e-02, -1.6037e-01,  3.2738e-01,  ..., -5.3661e-03,\n",
       "            -1.1580e-01, -2.6990e-01],\n",
       "           [-8.1421e-02, -2.0240e-01,  3.9247e-02,  ..., -1.5974e-01,\n",
       "            -1.5032e-01, -2.4295e-01],\n",
       "           [ 1.8059e-02, -2.0038e-01, -5.4908e-03,  ..., -5.1034e-02,\n",
       "            -4.5448e-02, -1.9630e-01]],\n",
       " \n",
       "          [[-9.4694e-02,  4.6168e-01,  5.9875e-01,  ...,  4.6843e-01,\n",
       "             2.9579e-01, -1.0078e-01],\n",
       "           [ 3.7546e-01,  1.4308e+00,  1.0985e+00,  ...,  8.1557e-01,\n",
       "             5.1170e-01, -1.8474e-01],\n",
       "           [ 1.1958e-01,  3.5246e-01,  1.0415e-01,  ...,  4.5882e-01,\n",
       "            -5.7397e-02, -2.7289e-01],\n",
       "           ...,\n",
       "           [-2.7602e-01, -2.1205e-01, -5.5563e-02,  ...,  1.5602e+00,\n",
       "             6.8683e-01,  7.8427e-03],\n",
       "           [-2.4084e-01, -2.7657e-01, -2.6190e-01,  ...,  1.6173e+00,\n",
       "             6.8166e-01, -2.6386e-01],\n",
       "           [-2.6510e-01, -2.6186e-01, -2.7361e-01,  ...,  3.4881e-01,\n",
       "            -6.7713e-02, -2.5618e-01]],\n",
       " \n",
       "          [[-2.4011e-01,  6.9233e-02,  2.4176e-01,  ...,  5.9968e-01,\n",
       "             4.3469e-01, -4.5627e-02],\n",
       "           [-2.7656e-01,  4.2208e-01,  3.4198e-01,  ...,  5.8340e-01,\n",
       "             2.3317e-01, -2.2431e-01],\n",
       "           [-2.4700e-01,  3.4666e-01,  3.2720e-01,  ...,  3.1974e-01,\n",
       "             4.5738e-01, -1.3501e-01],\n",
       "           ...,\n",
       "           [-2.7141e-01,  1.4022e-01,  8.4370e-02,  ...,  1.7754e+00,\n",
       "             1.1274e+00,  1.9783e-01],\n",
       "           [-2.7835e-01,  1.0775e-01,  5.9099e-02,  ...,  1.4451e+00,\n",
       "             5.4678e-01, -2.0721e-01],\n",
       "           [-1.7347e-01,  9.9129e-02, -3.7795e-02,  ...,  3.9514e-01,\n",
       "            -9.2721e-02, -2.3021e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.3849e-02,  2.3918e-02,  4.9352e-01,  ...,  5.4534e-01,\n",
       "             5.4034e-01,  2.0793e-01],\n",
       "           [ 6.4117e-01, -5.9252e-02,  1.3324e-01,  ...,  2.6005e-01,\n",
       "             2.5681e-01, -1.4174e-01],\n",
       "           [ 3.4470e-01, -1.1939e-01, -3.0611e-02,  ..., -1.3499e-03,\n",
       "            -1.5008e-04, -1.9878e-01],\n",
       "           ...,\n",
       "           [ 5.8778e-01,  2.1106e-01,  7.5985e-01,  ..., -2.7829e-01,\n",
       "            -2.7426e-01, -2.3767e-01],\n",
       "           [ 4.9996e-01,  1.3656e-01,  4.1097e-01,  ..., -2.3230e-01,\n",
       "            -2.6266e-01, -1.8384e-01],\n",
       "           [ 8.0001e-01,  3.7289e-01,  5.3564e-01,  ...,  3.8032e-01,\n",
       "             1.3703e-01,  2.0199e-01]],\n",
       " \n",
       "          [[-2.4172e-01, -2.7152e-01, -2.5870e-01,  ..., -7.0217e-02,\n",
       "            -2.2596e-02, -2.2838e-01],\n",
       "           [-2.7315e-01, -2.6134e-01, -2.6397e-01,  ..., -1.4131e-01,\n",
       "            -2.0966e-01, -2.7270e-01],\n",
       "           [-2.5710e-01, -2.7623e-01, -1.9971e-01,  ..., -2.7881e-02,\n",
       "            -2.0149e-01, -2.7833e-01],\n",
       "           ...,\n",
       "           [-2.6151e-01, -1.9464e-01, -1.0498e-01,  ...,  5.7257e-01,\n",
       "             6.3071e-01,  4.6040e-01],\n",
       "           [-2.5429e-01, -2.1516e-01, -4.0020e-02,  ...,  1.4946e+00,\n",
       "             1.0240e+00,  8.7968e-01],\n",
       "           [-1.3724e-01, -1.0634e-01, -6.4997e-02,  ...,  1.3816e+00,\n",
       "             8.9782e-01,  6.7934e-01]],\n",
       " \n",
       "          [[-3.8063e-02,  1.5348e-01,  5.0253e-01,  ...,  7.5255e-01,\n",
       "             6.6047e-01,  3.8374e-01],\n",
       "           [-1.9181e-01, -8.9781e-02,  2.7337e-01,  ...,  5.3270e-01,\n",
       "             2.7994e-01,  7.8423e-02],\n",
       "           [-5.4857e-02,  9.3033e-02,  5.5609e-01,  ...,  7.1694e-01,\n",
       "             3.7277e-01,  1.2601e-01],\n",
       "           ...,\n",
       "           [ 2.3876e-01,  3.1601e-01,  4.5679e-01,  ...,  1.4432e+00,\n",
       "             1.1565e+00,  1.1984e+00],\n",
       "           [ 4.3314e-01,  5.0291e-01,  7.0750e-01,  ...,  1.2902e+00,\n",
       "             9.1776e-01,  9.6786e-01],\n",
       "           [ 7.2919e-01,  8.3737e-01,  9.7607e-01,  ...,  1.5777e+00,\n",
       "             1.2227e+00,  1.2420e+00]]]], device='cuda:0',\n",
       "        grad_fn=<SiluBackward0>),\n",
       " tensor([[[[ 1.3950e+00,  1.3180e+00,  7.4840e-01,  ...,  9.5795e-01,\n",
       "             5.4504e-01,  5.4725e-01],\n",
       "           [ 1.0241e+00,  3.2116e-01, -3.6576e-02,  ..., -9.4483e-03,\n",
       "             1.0659e-02,  7.9962e-01],\n",
       "           [ 6.4926e-01,  2.0801e-02,  2.4367e-01,  ...,  1.7980e-01,\n",
       "             2.2411e-01,  6.8364e-01],\n",
       "           ...,\n",
       "           [ 1.7287e+00,  1.1062e+00,  5.7390e-01,  ...,  3.7768e-01,\n",
       "             1.5017e-01,  8.0212e-02],\n",
       "           [ 2.2574e+00,  2.0152e+00,  1.6636e+00,  ...,  5.4254e-01,\n",
       "             4.3986e-01,  8.4481e-02],\n",
       "           [ 2.1297e+00,  1.7151e+00,  1.0383e+00,  ...,  1.0657e+00,\n",
       "             2.1745e+00,  9.7610e-01]],\n",
       " \n",
       "          [[-1.0980e-01,  6.7804e-02,  1.2088e+00,  ...,  2.6000e-01,\n",
       "            -2.6316e-01, -1.5963e-01],\n",
       "           [-2.3388e-01, -1.9106e-01,  1.3505e-01,  ..., -7.9542e-02,\n",
       "            -2.0508e-01, -1.7049e-01],\n",
       "           [-1.0934e-01, -2.6735e-01, -2.7830e-01,  ..., -2.3912e-01,\n",
       "            -1.5636e-01,  1.8454e-02],\n",
       "           ...,\n",
       "           [ 4.1233e-01, -9.9822e-02, -2.7670e-01,  ..., -1.7472e-01,\n",
       "             7.7631e-02, -1.9947e-01],\n",
       "           [-1.9802e-01, -1.3392e-01, -6.3176e-02,  ...,  9.9975e-01,\n",
       "             4.9736e+00,  4.5833e+00],\n",
       "           [ 3.7853e-01,  1.4801e-01,  1.8588e-01,  ...,  7.6824e-01,\n",
       "             5.4631e+00,  5.1962e+00]],\n",
       " \n",
       "          [[-2.7826e-01, -2.3690e-01,  5.8386e-01,  ...,  1.1613e+00,\n",
       "             5.4375e-01,  4.6647e-01],\n",
       "           [-7.0506e-02, -2.1730e-01, -1.7034e-01,  ...,  1.2058e+00,\n",
       "             4.5218e-01,  4.8066e-01],\n",
       "           [ 3.5559e-01, -2.2794e-01, -1.2921e-01,  ...,  1.7797e-01,\n",
       "             8.8803e-01,  1.6802e+00],\n",
       "           ...,\n",
       "           [ 1.0136e+00, -7.4989e-02,  2.9999e-01,  ...,  3.3929e-01,\n",
       "             4.0355e-02,  3.2751e-01],\n",
       "           [ 2.0312e-02, -1.1522e-03, -2.6445e-01,  ..., -2.0701e-01,\n",
       "             5.4671e-02,  1.3909e-01],\n",
       "           [ 3.2746e+00,  1.7498e+00,  3.2812e-01,  ...,  4.7275e-01,\n",
       "             3.0110e+00,  2.7458e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.4080e-01, -1.0781e-01,  1.3544e-01,  ...,  4.0763e-01,\n",
       "            -7.4145e-02,  3.1933e-01],\n",
       "           [-2.2294e-01,  1.1108e-01, -2.2922e-01,  ..., -8.7556e-02,\n",
       "            -7.4449e-02, -2.3451e-02],\n",
       "           [-1.5400e-01,  1.4197e-02,  2.5656e-01,  ..., -1.7450e-01,\n",
       "            -1.2088e-01,  8.9137e-02],\n",
       "           ...,\n",
       "           [ 1.4012e+00,  7.7390e-01,  1.2195e-01,  ..., -2.3529e-01,\n",
       "            -2.1051e-01, -2.7621e-01],\n",
       "           [ 2.3213e+00,  1.5994e+00,  1.1211e+00,  ..., -2.7795e-01,\n",
       "            -2.7362e-01, -2.7791e-01],\n",
       "           [ 1.4115e+00,  1.4263e+00,  8.7937e-01,  ...,  3.7867e-01,\n",
       "             4.0854e-01,  2.7713e-01]],\n",
       " \n",
       "          [[ 1.0561e+00,  1.8003e-01, -5.4112e-02,  ..., -9.4021e-02,\n",
       "             1.5483e-01,  4.9627e-01],\n",
       "           [ 1.7020e+00,  3.4521e-01,  3.3571e-02,  ...,  3.7050e-01,\n",
       "            -5.2102e-03,  8.9023e-01],\n",
       "           [ 1.0818e+00,  4.2032e-02, -2.4037e-01,  ..., -2.3189e-01,\n",
       "             9.3016e-02, -5.6112e-02],\n",
       "           ...,\n",
       "           [ 1.6077e+00,  3.4158e-01,  1.4324e-01,  ..., -1.9423e-01,\n",
       "            -2.5095e-01, -2.7487e-01],\n",
       "           [ 1.6228e-01,  8.7143e-01,  2.8165e-01,  ...,  2.4753e-01,\n",
       "            -2.7690e-01, -4.2243e-02],\n",
       "           [ 6.9540e-02,  2.0287e-01,  6.5264e-01,  ...,  5.5382e-01,\n",
       "            -2.4594e-01, -2.5555e-01]],\n",
       " \n",
       "          [[ 5.5020e-01, -1.3183e-01,  3.3728e-01,  ...,  5.1060e-01,\n",
       "            -1.8739e-01, -2.4522e-01],\n",
       "           [-2.6490e-01, -2.5697e-01, -1.9178e-01,  ..., -2.7335e-01,\n",
       "            -2.4157e-01, -2.6407e-01],\n",
       "           [ 1.0354e-01, -2.6997e-01, -1.6983e-01,  ...,  5.5986e-02,\n",
       "            -1.8546e-01, -2.5734e-01],\n",
       "           ...,\n",
       "           [-2.5576e-01, -2.6126e-01,  6.0588e-01,  ..., -2.1095e-01,\n",
       "            -2.4976e-01, -2.7618e-01],\n",
       "           [-1.9054e-01, -2.7424e-01, -2.7705e-01,  ..., -2.6823e-01,\n",
       "             1.6118e-01,  2.9890e-01],\n",
       "           [-2.1652e-01, -2.7770e-01, -2.7795e-01,  ..., -9.0369e-02,\n",
       "            -2.7661e-01, -1.9282e-01]]]], device='cuda:0',\n",
       "        grad_fn=<SiluBackward0>),\n",
       " tensor([[[[ 0.9131,  1.6233,  1.3483,  ...,  0.5747,  1.9864,  1.7988],\n",
       "           [-0.1702,  0.6718,  0.6361,  ...,  0.5782,  2.6305,  0.2917],\n",
       "           [ 0.3963,  0.3783,  0.1578,  ...,  0.6721,  1.4370,  0.1088],\n",
       "           ...,\n",
       "           [ 0.2742,  0.7296,  0.2711,  ..., -0.0990,  1.0233,  1.7926],\n",
       "           [ 0.6120,  0.8668,  0.0948,  ...,  0.3766,  0.9445,  0.2739],\n",
       "           [ 0.6092,  0.1071,  0.5449,  ...,  0.5775,  1.1898,  1.0176]],\n",
       " \n",
       "          [[ 1.2372,  0.1839,  0.4219,  ...,  0.4386, -0.1555,  0.9514],\n",
       "           [-0.1294, -0.2587, -0.2178,  ..., -0.2136, -0.2164, -0.2444],\n",
       "           [ 0.2050, -0.1282, -0.2647,  ..., -0.2092, -0.2736, -0.2766],\n",
       "           ...,\n",
       "           [ 2.3284, -0.2784,  0.7569,  ...,  1.0840, -0.2614,  2.2875],\n",
       "           [ 1.0142, -0.0370, -0.0832,  ...,  1.6520,  0.0757,  0.5981],\n",
       "           [ 2.9679, -0.1425,  0.0467,  ...,  1.1846,  0.6291,  2.6554]],\n",
       " \n",
       "          [[ 2.6521,  2.2666,  2.2636,  ...,  0.6500,  3.4267,  3.6357],\n",
       "           [ 2.2469,  1.5534, -0.1508,  ..., -0.2772,  3.2526,  4.6434],\n",
       "           [ 0.0196,  2.7094,  0.8651,  ...,  0.0862,  1.6206,  1.4721],\n",
       "           ...,\n",
       "           [ 0.2131, -0.2305, -0.2768,  ..., -0.0917, -0.2749, -0.2154],\n",
       "           [ 0.9396,  0.0688, -0.2539,  ..., -0.2283, -0.2021, -0.1412],\n",
       "           [ 0.7434,  3.3209,  0.5844,  ..., -0.2321,  0.1049, -0.0630]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.2188,  1.2321,  0.3235,  ...,  0.6678, -0.2784,  1.8368],\n",
       "           [ 1.2571, -0.0493, -0.2713,  ...,  0.2378,  0.4504,  2.5749],\n",
       "           [ 0.1814,  1.6336, -0.2507,  ..., -0.0150,  0.1423,  2.1401],\n",
       "           ...,\n",
       "           [-0.0203,  1.0236, -0.1862,  ...,  0.2264,  0.1978, -0.2575],\n",
       "           [ 0.1262,  0.1043,  0.9711,  ...,  0.2508, -0.1527, -0.2031],\n",
       "           [ 0.5886,  1.1611,  0.3432,  ..., -0.2780, -0.0574, -0.2610]],\n",
       " \n",
       "          [[-0.2193, -0.2128, -0.2383,  ..., -0.2771, -0.1382, -0.1910],\n",
       "           [-0.2748, -0.0291, -0.0573,  ..., -0.2408,  0.1618, -0.2700],\n",
       "           [-0.1691,  0.0202,  0.2428,  ..., -0.0954, -0.0604, -0.0660],\n",
       "           ...,\n",
       "           [ 2.9174,  1.6113,  0.6806,  ...,  0.6860,  0.0827,  3.9535],\n",
       "           [ 1.8461,  1.9724,  1.4180,  ...,  1.2402,  0.8979,  2.0904],\n",
       "           [ 1.3532,  1.2133,  0.1258,  ...,  0.7782,  0.2381, -0.0837]],\n",
       " \n",
       "          [[ 0.4357,  1.1512,  1.1086,  ..., -0.2445,  4.0493,  0.0823],\n",
       "           [ 0.5127,  0.4183,  0.7146,  ..., -0.1867, -0.2710, -0.0970],\n",
       "           [-0.2427, -0.1466, -0.0883,  ..., -0.2705,  0.5232, -0.2499],\n",
       "           ...,\n",
       "           [-0.2769, -0.2732, -0.2467,  ..., -0.2185, -0.0526, -0.0492],\n",
       "           [-0.2784, -0.2440,  0.1042,  ..., -0.2752, -0.2057, -0.2070],\n",
       "           [-0.2597, -0.1404,  0.6501,  ...,  2.0284,  0.3873,  0.8806]]]],\n",
       "        device='cuda:0', grad_fn=<SiluBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17b376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
